{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Financial Crisis: Study B x Processing 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Financial Crises dataset: characterize/describe the dataset and compare various classification models (e.g., Logistic regression, SVM, NN, classification trees/forests, ... ) in terms of their ability to correctly predict financial crises. Make sure to treat this as a real-time prediction problem: when predicting financial crises is a given year t, you can only use features from previous years t-s (with s>0), but no contemporaneous variables from the same year t. Compare the quality of your predictions using different criteria and validation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, r2_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, average_precision_score\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinancialCrises.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['country'] == 'DNK']\n",
    "df2 = df.loc[df['country'] == 'AUS']\n",
    "df3 = df.loc[df['country'] == 'JPN']\n",
    "df4 = df.loc[df['country'] == 'ESP']\n",
    "df5 = df.loc[df['country'] == 'GBR']\n",
    "df6 = df.loc[df['country'] == 'SWE']\n",
    "df7 = df.loc[df['country'] == 'FRA']\n",
    "df8 = df.loc[df['country'] == 'NOR']\n",
    "df9 = df.loc[df['country'] == 'USA']\n",
    "df10 = df.loc[df['country'] == 'ITA']\n",
    "df11 = df.loc[df['country'] == 'DEU']\n",
    "df12 = df.loc[df['country'] == 'CAN']\n",
    "df13 = df.loc[df['country'] == 'NLD']\n",
    "df14 = df.loc[df['country'] == 'CHE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_process(df):\n",
    "    df['loans1'] = df['loans1'].fillna(method = 'ffill')\n",
    "    df['loans1'] = df['loans1'].fillna(method = 'bfill')\n",
    "    df['bassets2'] = df['bassets2'].fillna(method = 'ffill')\n",
    "    df['bassets2'] = df['bassets2'].fillna(method = 'bfill')\n",
    "    df['narrowm'] = df['narrowm'].fillna(method = 'ffill')\n",
    "    df['narrowm'] = df['narrowm'].fillna(method = 'bfill')\n",
    "    df['money'] = df['money'].fillna(method = 'ffill')\n",
    "    df['money'] = df['money'].fillna(method = 'bfill')\n",
    "    df['gdp'] = df['gdp'].fillna(method = 'ffill')\n",
    "    df['gdp'] = df['gdp'].fillna(method = 'bfill')\n",
    "    df['iy'] = df['iy'].fillna(method = 'ffill')\n",
    "    df['iy'] = df['iy'].fillna(method = 'bfill')\n",
    "    df['cpi'] = df['cpi'].fillna(method = 'ffill')\n",
    "    df['cpi'] = df['cpi'].fillna(method = 'bfill')\n",
    "    df['stir'] = df['stir'].fillna(method = 'ffill')\n",
    "    df['stir'] = df['stir'].fillna(method = 'bfill')\n",
    "    df['ltrate'] = df['ltrate'].fillna(method = 'ffill')\n",
    "    df['ltrate'] = df['ltrate'].fillna(method = 'bfill')\n",
    "    df['stocks'] = df['stocks'].fillna(method = 'ffill')\n",
    "    df['stocks'] = df['stocks'].fillna(method = 'bfill')\n",
    "    df = df.sort_values(by=['country', 'year'])\n",
    "    df['credit_growth'] = np.log(df['loans1']).diff() - np.log(df['cpi']).diff()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_process(df1)\n",
    "df2 = df_process(df2)\n",
    "df3 = df_process(df3)\n",
    "df4 = df_process(df4)\n",
    "df5 = df_process(df5)\n",
    "df6 = df_process(df6)\n",
    "df7 = df_process(df7)\n",
    "df8 = df_process(df8)\n",
    "df9 = df_process(df9)\n",
    "df10 = df_process(df10)\n",
    "df11 = df_process(df11)\n",
    "df12 = df_process(df12)\n",
    "df13 = df_process(df13)\n",
    "df14 = df_process(df14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14])\n",
    "enc = LabelEncoder()\n",
    "df['country'] = enc.fit_transform(df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = ['rgdpbarro', 'rgdp', 'loans1', 'bassets2', 'narrowm',\n",
    "       'money', 'gdp', 'iy', 'cpi', 'pop', 'stir', 'ltrate', 'stocks', 'credit_growth']\n",
    "not_scaled_features = ['year', 'country', 'crisisST']\n",
    "scale = StandardScaler()\n",
    "df1 = pd.DataFrame(scale.fit_transform(df[scaled_features]), columns = scaled_features, index = df.index)\n",
    "df2 = df[not_scaled_features]\n",
    "df = df1.merge(df2, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.sort_values(by=['year', 'country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "df = df.set_index(np.arange(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rgdpbarro</th>\n",
       "      <th>rgdp</th>\n",
       "      <th>loans1</th>\n",
       "      <th>bassets2</th>\n",
       "      <th>narrowm</th>\n",
       "      <th>money</th>\n",
       "      <th>gdp</th>\n",
       "      <th>iy</th>\n",
       "      <th>cpi</th>\n",
       "      <th>pop</th>\n",
       "      <th>stir</th>\n",
       "      <th>ltrate</th>\n",
       "      <th>stocks</th>\n",
       "      <th>credit_growth</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>crisisST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.727692</td>\n",
       "      <td>-0.703029</td>\n",
       "      <td>-0.102159</td>\n",
       "      <td>-0.109411</td>\n",
       "      <td>-0.097514</td>\n",
       "      <td>-0.114157</td>\n",
       "      <td>-0.116693</td>\n",
       "      <td>-1.207968</td>\n",
       "      <td>-0.647709</td>\n",
       "      <td>-0.758864</td>\n",
       "      <td>-0.037921</td>\n",
       "      <td>-0.297219</td>\n",
       "      <td>-0.239043</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>1871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.964185</td>\n",
       "      <td>-0.930557</td>\n",
       "      <td>-0.102169</td>\n",
       "      <td>-0.109420</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.114164</td>\n",
       "      <td>-0.116707</td>\n",
       "      <td>-0.461455</td>\n",
       "      <td>-0.562028</td>\n",
       "      <td>-0.712282</td>\n",
       "      <td>-0.629953</td>\n",
       "      <td>-0.266696</td>\n",
       "      <td>-0.188398</td>\n",
       "      <td>0.247946</td>\n",
       "      <td>1871</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.687977</td>\n",
       "      <td>-0.861171</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>-0.109314</td>\n",
       "      <td>-0.097481</td>\n",
       "      <td>-0.114051</td>\n",
       "      <td>-0.116584</td>\n",
       "      <td>-1.764803</td>\n",
       "      <td>-0.384167</td>\n",
       "      <td>-0.736844</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>-0.833212</td>\n",
       "      <td>-0.233139</td>\n",
       "      <td>-0.167597</td>\n",
       "      <td>1871</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.833400</td>\n",
       "      <td>-0.921415</td>\n",
       "      <td>-0.102167</td>\n",
       "      <td>-0.109419</td>\n",
       "      <td>-0.097523</td>\n",
       "      <td>-0.114163</td>\n",
       "      <td>-0.116705</td>\n",
       "      <td>-1.323061</td>\n",
       "      <td>-0.709234</td>\n",
       "      <td>0.068946</td>\n",
       "      <td>-0.383425</td>\n",
       "      <td>-0.438822</td>\n",
       "      <td>-0.234819</td>\n",
       "      <td>-0.092535</td>\n",
       "      <td>1871</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.913081</td>\n",
       "      <td>-0.895409</td>\n",
       "      <td>-0.102169</td>\n",
       "      <td>-0.109420</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.114164</td>\n",
       "      <td>-0.116707</td>\n",
       "      <td>-0.897426</td>\n",
       "      <td>-0.639152</td>\n",
       "      <td>-0.753869</td>\n",
       "      <td>-0.189117</td>\n",
       "      <td>-0.318447</td>\n",
       "      <td>-0.238793</td>\n",
       "      <td>-0.142166</td>\n",
       "      <td>1871</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rgdpbarro      rgdp    loans1  bassets2   narrowm     money       gdp  \\\n",
       "0  -0.727692 -0.703029 -0.102159 -0.109411 -0.097514 -0.114157 -0.116693   \n",
       "1  -0.964185 -0.930557 -0.102169 -0.109420 -0.097524 -0.114164 -0.116707   \n",
       "2  -0.687977 -0.861171 -0.101381 -0.109314 -0.097481 -0.114051 -0.116584   \n",
       "3  -0.833400 -0.921415 -0.102167 -0.109419 -0.097523 -0.114163 -0.116705   \n",
       "4  -0.913081 -0.895409 -0.102169 -0.109420 -0.097524 -0.114164 -0.116707   \n",
       "\n",
       "         iy       cpi       pop      stir    ltrate    stocks  credit_growth  \\\n",
       "0 -1.207968 -0.647709 -0.758864 -0.037921 -0.297219 -0.239043      -0.001519   \n",
       "1 -0.461455 -0.562028 -0.712282 -0.629953 -0.266696 -0.188398       0.247946   \n",
       "2 -1.764803 -0.384167 -0.736844 -0.274734 -0.833212 -0.233139      -0.167597   \n",
       "3 -1.323061 -0.709234  0.068946 -0.383425 -0.438822 -0.234819      -0.092535   \n",
       "4 -0.897426 -0.639152 -0.753869 -0.189117 -0.318447 -0.238793      -0.142166   \n",
       "\n",
       "   year  country  crisisST  \n",
       "0  1871        0         0  \n",
       "1  1871        1         0  \n",
       "2  1871        2         0  \n",
       "3  1871        3         0  \n",
       "4  1871        4         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 200, solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4833240997229917\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7000891265597148\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.78125\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49381038647343\n",
      "Confusion_Matrix 4\n",
      "[[360   8]\n",
      " [ 17   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5234349030470915\n",
      "Confusion_Matrix 1\n",
      "[[357   4]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6653297682709447\n",
      "Confusion_Matrix 2\n",
      "[[346  28]\n",
      " [ 10   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7330729166666667\n",
      "Confusion_Matrix 3\n",
      "[[374  10]\n",
      " [  1   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.491243961352657\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(criterion = 'entropy', max_features = 'auto', min_samples_leaf = 2, min_samples_split = 2,\n",
    "                            n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5193351800554017\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6842691622103387\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6966145833333334\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6402475845410628\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5181717451523546\n",
      "Confusion_Matrix 1\n",
      "[[341  20]\n",
      " [ 23   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6183155080213903\n",
      "Confusion_Matrix 2\n",
      "[[367   7]\n",
      " [ 10   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.59765625\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5333635265700483\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(criterion = 'entropy', max_features = 'auto', min_samples_leaf = 2, min_samples_split = 2,\n",
    "                            n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5330193905817175\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5786541889483066\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7636718750000001\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6136020531400965\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5065927977839335\n",
      "Confusion_Matrix 1\n",
      "[[353   8]\n",
      " [ 23   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49376114081996436\n",
      "Confusion_Matrix 2\n",
      "[[358  16]\n",
      " [ 10   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5270984299516909\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.48814404432132963\n",
      "Confusion_Matrix 1\n",
      "[[338  23]\n",
      " [ 24   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4788324420677361\n",
      "Confusion_Matrix 2\n",
      "[[327  47]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7330729166666667\n",
      "Confusion_Matrix 3\n",
      "[[179 205]\n",
      " [  0   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49592391304347827\n",
      "Confusion_Matrix 4\n",
      "[[365   3]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5064265927977839\n",
      "Confusion_Matrix 1\n",
      "[[279  82]\n",
      " [ 19   6]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4723707664884136\n",
      "Confusion_Matrix 2\n",
      "[[291  83]\n",
      " [ 10   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4088541666666667\n",
      "Confusion_Matrix 3\n",
      "[[314  70]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49320652173913043\n",
      "Confusion_Matrix 4\n",
      "[[363   5]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5109141274238227\n",
      "Confusion_Matrix 1\n",
      "[[350  11]\n",
      " [ 23   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5689616755793226\n",
      "Confusion_Matrix 2\n",
      "[[366   8]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.96484375\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5179649758454106\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.47412742382271467\n",
      "Confusion_Matrix 1\n",
      "[[264  97]\n",
      " [ 18   7]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5940285204991087\n",
      "Confusion_Matrix 2\n",
      "[[369   5]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.22395833333333331\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5344202898550724\n",
      "Confusion_Matrix 4\n",
      "[[365   3]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6218282548476455\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6127450980392156\n",
      "Confusion_Matrix 2\n",
      "[[371   3]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.8072916666666666\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5464975845410628\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6342382271468144\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.625668449197861\n",
      "Confusion_Matrix 2\n",
      "[[363  11]\n",
      " [ 10   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5006510416666666\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5074728260869565\n",
      "Confusion_Matrix 4\n",
      "[[367   1]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.546759002770083\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6031639928698752\n",
      "Confusion_Matrix 2\n",
      "[[371   3]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.8815104166666666\n",
      "Confusion_Matrix 3\n",
      "[[375   9]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5406099033816425\n",
      "Confusion_Matrix 4\n",
      "[[366   2]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4846537396121884\n",
      "Confusion_Matrix 1\n",
      "[[312  49]\n",
      " [ 21   4]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6864973262032086\n",
      "Confusion_Matrix 2\n",
      "[[369   5]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.46354166666666663\n",
      "Confusion_Matrix 3\n",
      "[[381   3]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5350241545893719\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = y_proba[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "from sklearn.utils.fixes import signature\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.subplot(2,1,2)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "auc_score = roc_auc_score(y_test, y_score)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve: AUC Score = {0:0.2f}'.format(\n",
    "          auc_score))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4600000000000001\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6086229946524064\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7513020833333334\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6564764492753623\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.47700831024930745\n",
      "Confusion_Matrix 1\n",
      "[[340  21]\n",
      " [ 22   3]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7088903743315508\n",
      "Confusion_Matrix 2\n",
      "[[368   6]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5546875\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5052838164251208\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.45927977839335177\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5772058823529412\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7005208333333334\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5128321256038647\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4493628808864266\n",
      "Confusion_Matrix 1\n",
      "[[294  67]\n",
      " [ 21   4]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5508021390374331\n",
      "Confusion_Matrix 2\n",
      "[[318  56]\n",
      " [  8   4]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6829427083333334\n",
      "Confusion_Matrix 3\n",
      "[[369  15]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5126056763285024\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5341828254847646\n",
      "Confusion_Matrix 1\n",
      "[[310  51]\n",
      " [ 20   5]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.67825311942959\n",
      "Confusion_Matrix 2\n",
      "[[324  50]\n",
      " [  9   3]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.31770833333333337\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4973580917874396\n",
      "Confusion_Matrix 4\n",
      "[[342  26]\n",
      " [ 17   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5772853185595568\n",
      "Confusion_Matrix 1\n",
      "[[319  42]\n",
      " [ 20   5]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.6695632798573975\n",
      "Confusion_Matrix 2\n",
      "[[300  74]\n",
      " [  7   5]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.291015625\n",
      "Confusion_Matrix 3\n",
      "[[383   1]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.46150362318840576\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5864819944598338\n",
      "Confusion_Matrix 1\n",
      "[[339  22]\n",
      " [ 23   2]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5084670231729055\n",
      "Confusion_Matrix 2\n",
      "[[333  41]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.30598958333333337\n",
      "Confusion_Matrix 3\n",
      "[[368  16]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.46769323671497587\n",
      "Confusion_Matrix 4\n",
      "[[358  10]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5946814404432134\n",
      "Confusion_Matrix 1\n",
      "[[303  58]\n",
      " [ 20   5]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.553475935828877\n",
      "Confusion_Matrix 2\n",
      "[[280  94]\n",
      " [  9   3]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.203125\n",
      "Confusion_Matrix 3\n",
      "[[354  30]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49554649758454106\n",
      "Confusion_Matrix 4\n",
      "[[345  23]\n",
      " [ 17   1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.37385041551246534\n",
      "Confusion_Matrix 1\n",
      "[[346  15]\n",
      " [ 24   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5641711229946524\n",
      "Confusion_Matrix 2\n",
      "[[361  13]\n",
      " [ 11   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.359375\n",
      "Confusion_Matrix 3\n",
      "[[383   1]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.509963768115942\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.38847645429362887\n",
      "Confusion_Matrix 1\n",
      "[[353   8]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5708556149732621\n",
      "Confusion_Matrix 2\n",
      "[[366   8]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.3684895833333333\n",
      "Confusion_Matrix 3\n",
      "[[383   1]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5384963768115942\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.45451523545706374\n",
      "Confusion_Matrix 1\n",
      "[[361   0]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.28141711229946526\n",
      "Confusion_Matrix 2\n",
      "[[374   0]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.9557291666666666\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.47969504830917875\n",
      "Confusion_Matrix 4\n",
      "[[365   3]\n",
      " [ 18   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5748476454293628\n",
      "Confusion_Matrix 1\n",
      "[[303  58]\n",
      " [ 18   7]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.7364081996434937\n",
      "Confusion_Matrix 2\n",
      "[[355  19]\n",
      " [  8   4]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.10286458333333331\n",
      "Confusion_Matrix 3\n",
      "[[384   0]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4819595410628019\n",
      "Confusion_Matrix 4\n",
      "[[368   0]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss = 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_sm = []\n",
    "AUC_LR = []\n",
    "proba_sm = []\n",
    "proba = []\n",
    "y_t = []\n",
    "y = df['crisisST'].values\n",
    "X = df.drop(['crisisST'], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X  = scaler.fit_transform(X)\n",
    "sm = SMOTE(0.5,random_state=42)\n",
    "tscv = TimeSeriesSplit(n_splits=n)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_t.append(y_test)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    clf.fit(X_train_sm, y_train_sm)\n",
    "    y_proba1 = clf.predict_proba(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    AUC_LR.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "    proba.append(list(y_proba[:,1]))\n",
    "    AUC_LR_sm.append(roc_auc_score(y_test, y_proba1[:,1]))\n",
    "    proba_sm.append(list(y_proba1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5499168975069252\n",
      "Confusion_Matrix 1\n",
      "[[352   9]\n",
      " [ 25   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.5251782531194296\n",
      "Confusion_Matrix 2\n",
      "[[373   1]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.203125\n",
      "Confusion_Matrix 3\n",
      "[[302  82]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49169685990338163\n",
      "Confusion_Matrix 4\n",
      "[[336  32]\n",
      " [ 17   1]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.4503047091412743\n",
      "Confusion_Matrix 1\n",
      "[[170 191]\n",
      " [ 15  10]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.625222816399287\n",
      "Confusion_Matrix 2\n",
      "[[353  21]\n",
      " [ 12   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.23177083333333331\n",
      "Confusion_Matrix 3\n",
      "[[343  41]\n",
      " [  2   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "AUC Score: 0.49924516908212563\n",
      "Confusion_Matrix 4\n",
      "[[365   3]\n",
      " [ 18   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conf_mat(prob, AUC):\n",
    "    for i in range(n):\n",
    "        y_pred = []\n",
    "        for j in range(len(prob[i])):\n",
    "            if prob[i][j]>0.5:\n",
    "                y_pred.append(1)\n",
    "            else: \n",
    "                y_pred.append(0)\n",
    "        print( \"-\"*80)\n",
    "        print('AUC Score:', AUC[i])\n",
    "        print('Confusion_Matrix', i+1)\n",
    "        print(confusion_matrix(y_t[i],y_pred))\n",
    "conf_mat(proba, AUC_LR), conf_mat(proba_sm, AUC_LR_sm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
